Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.92 GB / 5.82 GB (15.8%)
Disk Space Avail:   31.42 GB / 222.38 GB (14.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc ',
 'time_limit': 600,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="autogluon-m4-hourly"
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon-m4-hourly'
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.57 GB / 5.82 GB (9.8%)
Disk Space Avail:   31.41 GB / 222.38 GB (14.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.57 GB / 5.82 GB (9.8%)
Disk Space Avail:   31.41 GB / 222.38 GB (14.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.41 GB / 5.82 GB (7.0%)
Disk Space Avail:   36.98 GB / 222.38 GB (16.6%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="autogluon"
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.73 GB / 5.82 GB (12.5%)
Disk Space Avail:   36.98 GB / 222.38 GB (16.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.73 GB / 5.82 GB (12.5%)
Disk Space Avail:   36.98 GB / 222.38 GB (16.6%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Inferred time series frequency: 's'
Inferred time series frequency: 's'
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 

Provided data contains following columns:

Provided data contains following columns:
	target: 'grip_lost_enc'
	target: 'grip_lost_enc'
	past_covariates:
	past_covariates:
		categorical:        []
		categorical:        []
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-03-20 15:14:51

Starting training. Start time is 2025-03-20 15:14:51
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 66.3s of the 596.5s of remaining time.
Training timeseries model Naive. Training for up to 66.3s of the 596.5s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.11    s     = Training runtime
	0.11    s     = Training runtime
	12.15   s     = Validation (prediction) runtime
	12.15   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 73.0s of the 584.1s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 73.0s of the 584.1s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.11    s     = Training runtime
	0.11    s     = Training runtime
	4.90    s     = Validation (prediction) runtime
	4.90    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 82.7s of the 579.1s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 82.7s of the 579.1s of remaining time.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 96.1s of the 576.8s of remaining time.
Training timeseries model DirectTabular. Training for up to 96.1s of the 576.8s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 115.0s of the 574.9s of remaining time.
Training timeseries model ETS. Training for up to 115.0s of the 574.9s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.12    s     = Training runtime
	0.12    s     = Training runtime
	6.43    s     = Validation (prediction) runtime
	6.43    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 142.1s of the 568.3s of remaining time.
Training timeseries model Theta. Training for up to 142.1s of the 568.3s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.13    s     = Training runtime
	0.13    s     = Training runtime
	42.61   s     = Validation (prediction) runtime
	42.61   s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. Training for up to 175.2s of the 525.5s of remaining time.
Training timeseries model Chronos[bolt_small]. Training for up to 175.2s of the 525.5s of remaining time.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
Training timeseries model TemporalFusionTransformer. Training for up to 252.7s of the 505.4s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 252.7s of the 505.4s of remaining time.
	Warning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.
	Warning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.
	[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 40189300736 bytes.
	[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 40189300736 bytes.
Fitting simple weighted ensemble.
Fitting simple weighted ensemble.
	Warning: Exception caused ensemble to fail during training... Skipping this model.
	Warning: Exception caused ensemble to fail during training... Skipping this model.
	'a' cannot be empty unless no samples are taken
	'a' cannot be empty unless no samples are taken
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta']
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta']
Total runtime: 199.36 s
Total runtime: 199.36 s
Best model: Naive
Best model: Naive
Best model score: nan
Best model score: nan
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.86 GB / 5.82 GB (14.7%)
Disk Space Avail:   30.97 GB / 222.38 GB (13.9%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.86 GB / 5.82 GB (14.7%)
Disk Space Avail:   30.97 GB / 222.38 GB (13.9%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.86 GB / 5.82 GB (14.7%)
Disk Space Avail:   30.97 GB / 222.38 GB (13.9%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Inferred time series frequency: 's'
Inferred time series frequency: 's'
Inferred time series frequency: 's'
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'grip_lost_enc'
	target: 'grip_lost_enc'
	target: 'grip_lost_enc'
	past_covariates:
	past_covariates:
	past_covariates:
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================

Starting training. Start time is 2025-03-21 11:15:31

Starting training. Start time is 2025-03-21 11:15:31

Starting training. Start time is 2025-03-21 11:15:31
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 66.6s of the 599.8s of remaining time.
Training timeseries model Naive. Training for up to 66.6s of the 599.8s of remaining time.
Training timeseries model Naive. Training for up to 66.6s of the 599.8s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.10    s     = Training runtime
	0.10    s     = Training runtime
	0.10    s     = Training runtime
	13.05   s     = Validation (prediction) runtime
	13.05   s     = Validation (prediction) runtime
	13.05   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 73.3s of the 586.5s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 73.3s of the 586.5s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 73.3s of the 586.5s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.06    s     = Training runtime
	0.06    s     = Training runtime
	0.06    s     = Training runtime
	8.55    s     = Validation (prediction) runtime
	8.55    s     = Validation (prediction) runtime
	8.55    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 82.5s of the 577.8s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 82.5s of the 577.8s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 82.5s of the 577.8s of remaining time.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 93.1s of the 558.9s of remaining time.
Training timeseries model DirectTabular. Training for up to 93.1s of the 558.9s of remaining time.
Training timeseries model DirectTabular. Training for up to 93.1s of the 558.9s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 111.1s of the 555.7s of remaining time.
Training timeseries model ETS. Training for up to 111.1s of the 555.7s of remaining time.
Training timeseries model ETS. Training for up to 111.1s of the 555.7s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.07    s     = Training runtime
	0.07    s     = Training runtime
	0.07    s     = Training runtime
	6.51    s     = Validation (prediction) runtime
	6.51    s     = Validation (prediction) runtime
	6.51    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 137.3s of the 549.1s of remaining time.
Training timeseries model Theta. Training for up to 137.3s of the 549.1s of remaining time.
Training timeseries model Theta. Training for up to 137.3s of the 549.1s of remaining time.
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	nan           = Validation score (-MASE)
	0.05    s     = Training runtime
	0.05    s     = Training runtime
	0.05    s     = Training runtime
	52.00   s     = Validation (prediction) runtime
	52.00   s     = Validation (prediction) runtime
	52.00   s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. Training for up to 165.7s of the 497.0s of remaining time.
Training timeseries model Chronos[bolt_small]. Training for up to 165.7s of the 497.0s of remaining time.
Training timeseries model Chronos[bolt_small]. Training for up to 165.7s of the 497.0s of remaining time.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
Training timeseries model TemporalFusionTransformer. Training for up to 248.3s of the 496.6s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 248.3s of the 496.6s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 248.3s of the 496.6s of remaining time.
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.36 GB / 5.82 GB (6.2%)
Disk Space Avail:   32.83 GB / 222.38 GB (14.8%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Inferred time series frequency: 's'
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 

Provided data contains following columns:
	target: 'grip_lost_enc'
	past_covariates:
		categorical:        []
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-03-21 11:38:59
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 60.6s of the 545.3s of remaining time.
	nan           = Validation score (-MASE)
	0.13    s     = Training runtime
	33.29   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 64.0s of the 511.8s of remaining time.
	nan           = Validation score (-MASE)
	0.09    s     = Training runtime
	16.58   s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 70.7s of the 495.1s of remaining time.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 76.7s of the 460.3s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 91.2s of the 456.0s of remaining time.
	nan           = Validation score (-MASE)
	0.16    s     = Training runtime
	21.30   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 108.6s of the 434.5s of remaining time.
	nan           = Validation score (-MASE)
	0.09    s     = Training runtime
	70.19   s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. Training for up to 121.4s of the 364.1s of remaining time.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
Training timeseries model TemporalFusionTransformer. Training for up to 170.8s of the 341.5s of remaining time.
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'c:\Users\USER-1\Downloads\test\final project\autogluon'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          4
GPU Count:          0
Memory Avail:       0.83 GB / 5.82 GB (14.3%)
Disk Space Avail:   34.46 GB / 222.38 GB (15.5%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 6014,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'grip_lost_enc',
 'time_limit': 600,
 'verbosity': 2}

Inferred time series frequency: 's'
Provided train_data has 24055 rows (NaN fraction=78.4%), 183 time series. Median time series length is 25 (min=11, max=18836). 
	Removing 182 short time series from train_data. Only series with length >= 12029 will be used for training.
	After filtering, train_data has 18836 rows (NaN fraction=99.9%), 1 time series. Median time series length is 18836 (min=18836, max=18836). 

Provided data contains following columns:
	target: 'grip_lost_enc'
	past_covariates:
		categorical:        []
		continuous (float): ['Current_J0', 'Temperature_T0', 'Current_J1', 'Temperature_J1', 'Current_J2', 'Temperature_J2', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-03-21 12:05:20
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 65.3s of the 587.7s of remaining time.
	nan           = Validation score (-MASE)
	0.11    s     = Training runtime
	10.77   s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 72.1s of the 576.8s of remaining time.
	nan           = Validation score (-MASE)
	0.05    s     = Training runtime
	6.37    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 81.5s of the 570.4s of remaining time.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model DirectTabular. Training for up to 92.1s of the 552.4s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.
Training timeseries model ETS. Training for up to 110.0s of the 549.9s of remaining time.
	nan           = Validation score (-MASE)
	0.07    s     = Training runtime
	5.41    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 136.1s of the 544.4s of remaining time.
	nan           = Validation score (-MASE)
	0.06    s     = Training runtime
	52.92   s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. Training for up to 163.8s of the 491.4s of remaining time.
	Warning: Exception caused Chronos[bolt_small] to fail during training... Skipping this model.
	Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):
Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):
Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.
Training timeseries model TemporalFusionTransformer. Training for up to 238.8s of the 477.5s of remaining time.
	Warning: Exception caused TemporalFusionTransformer to fail during training... Skipping this model.
	[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 40189300736 bytes.
Fitting simple weighted ensemble.
	Warning: Exception caused ensemble to fail during training... Skipping this model.
	'a' cannot be empty unless no samples are taken
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta']
Total runtime: 269.70 s
Best model: Naive
Best model score: nan
